{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "003d3879",
   "metadata": {},
   "source": [
    "# Подготовка модели распознавания рукописных букв и цифр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec09d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import EMNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Normalize\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edbfffb",
   "metadata": {},
   "source": [
    "### Загрузка и визуализация данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f8826a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразования изображений: конвертация в тензор и нормализация\n",
    "transform = Compose([ToTensor(), Normalize([0.5], [0.5])])\n",
    "\n",
    "# Загрузка набора данных EMNIST\n",
    "dataset = EMNIST('data/', 'balanced', download=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd45e608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загружаем соответствия между лейблами и символами\n",
    "def load_mapping(mapping_path):\n",
    "    label_to_char = {}\n",
    "    with open(mapping_path, 'r') as f:\n",
    "        for line in f:\n",
    "            label, char = line.strip().split()\n",
    "            label_to_char[int(label)] = chr(int(char))\n",
    "    return label_to_char\n",
    "\n",
    "mapping_path = 'emnist-balanced-mapping.txt'\n",
    "label_to_char = load_mapping(mapping_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "712aa6b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Преобразования для отображения\n",
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"Возвращает изображение в исходном формате (до нормализации).\"\"\"\n",
    "    mean = np.array(mean).reshape(1, 1, 1)\n",
    "    std = np.array(std).reshape(1, 1, 1)\n",
    "    tensor = tensor * std + mean\n",
    "    return tensor\n",
    "\n",
    "def show_images(dataset, label_to_char, num_images=5):\n",
    "    \"\"\"Отображает несколько изображений из набора данных с соответствующими метками.\"\"\"\n",
    "    data_loader = DataLoader(dataset, batch_size=num_images, shuffle=True)\n",
    "    images, labels = next(iter(data_loader))\n",
    "    \n",
    "    # Сопоставление меток с символами\n",
    "    labels = labels.numpy()\n",
    "    images = images.numpy()\n",
    "\n",
    "    # Параметры для отображения\n",
    "    num_cols = min(num_images, 5)\n",
    "    num_rows = (num_images + num_cols - 1) // num_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(12, 5))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(num_images):\n",
    "        image = denormalize(images[i], [0.5], [0.5]).squeeze() \n",
    "        label = label_to_char.get(labels[i], 'Unknown')\n",
    "\n",
    "        axes[i].imshow(image, cmap='gray')\n",
    "        axes[i].set_title(f'Label: {label}')\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "mapping_path = 'emnist-balanced-mapping.txt'\n",
    "label_to_char = load_mapping(mapping_path)\n",
    "\n",
    "show_images(dataset, label_to_char, num_images=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72988b52",
   "metadata": {},
   "source": [
    "### Подготовка данных для обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e491bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделение данных на обучающую и валидационную выборки\n",
    "train_dataset = EMNIST('data/', 'balanced', train=True, download=False, transform=transform)\n",
    "val_dataset = EMNIST('data/', 'balanced', train=False, download=False, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392e520",
   "metadata": {},
   "source": [
    "### Определение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ac2d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.Dropout(0.25),\n",
    "\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=64 * 7 * 7, out_features=128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(in_features=128, out_features=n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "model = CNN(47) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f23ddf1",
   "metadata": {},
   "source": [
    "### Определение функций обучения и валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c9352c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция обучения\n",
    "def train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre):\n",
    "    best_acc = 0\n",
    "    patience = 3 \n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(n_epoch):\n",
    "        model.train()\n",
    "        loss_sum = 0\n",
    "        print(f'Epoch: {epoch+1}/{n_epoch}')\n",
    "        for step, (data, target) in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_f(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_sum += loss.item()\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                print(f'Iter: {step} \\tLoss: {loss.item()}')\n",
    "\n",
    "        print(f'Mean Train Loss: {loss_sum / (step + 1):.6f}\\n')\n",
    "\n",
    "        # Валидация и ранняя остановка\n",
    "        if epoch % val_fre == 0:\n",
    "            val_acc = validate(model, val_loader)\n",
    "            if val_acc > best_acc:\n",
    "                best_acc = val_acc\n",
    "                torch.save(model.state_dict(), 'model.ckpt')\n",
    "                wait = 0\n",
    "            else:\n",
    "                wait += 1\n",
    "                if wait >= patience:\n",
    "                    print(f'Ранняя остановка на {epoch+1} эпохе')\n",
    "                    break\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    loss_sum = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for step, (data, target) in enumerate(val_loader):\n",
    "            output = model(data)\n",
    "            loss = loss_f(output, target)\n",
    "            loss_sum += loss.item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    acc = correct / len(val_loader.dataset)\n",
    "    print(f'Val Loss: {loss_sum / (step + 1):.6f} \\tAccuracy: {acc:.2f}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27e5a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/20\n",
      "Iter: 0 \tLoss: 0.5555078387260437\n",
      "Iter: 10 \tLoss: 0.5319530963897705\n",
      "Iter: 20 \tLoss: 0.6529417037963867\n",
      "Iter: 30 \tLoss: 0.5579660534858704\n",
      "Iter: 40 \tLoss: 0.7035213708877563\n",
      "Iter: 50 \tLoss: 0.6420392394065857\n",
      "Iter: 60 \tLoss: 0.5872600078582764\n",
      "Iter: 70 \tLoss: 0.5974962115287781\n",
      "Iter: 80 \tLoss: 0.5766079425811768\n",
      "Iter: 90 \tLoss: 0.5564576983451843\n",
      "Iter: 100 \tLoss: 0.5749028325080872\n",
      "Iter: 110 \tLoss: 0.5368410348892212\n",
      "Iter: 120 \tLoss: 0.5570236444473267\n",
      "Iter: 130 \tLoss: 0.5990203619003296\n",
      "Iter: 140 \tLoss: 0.5566893815994263\n",
      "Iter: 150 \tLoss: 0.6034066081047058\n",
      "Iter: 160 \tLoss: 0.5918940901756287\n",
      "Iter: 170 \tLoss: 0.5676255822181702\n",
      "Iter: 180 \tLoss: 0.44827336072921753\n",
      "Iter: 190 \tLoss: 0.4952164888381958\n",
      "Iter: 200 \tLoss: 0.5222618579864502\n",
      "Iter: 210 \tLoss: 0.5601749420166016\n",
      "Iter: 220 \tLoss: 0.46244102716445923\n",
      "Mean Train Loss: 0.582258\n",
      "\n",
      "Val Loss: 0.399373 \tAccuracy: 0.86\n",
      "Epoch: 2/20\n",
      "Iter: 0 \tLoss: 0.4946211278438568\n",
      "Iter: 10 \tLoss: 0.4662303626537323\n",
      "Iter: 20 \tLoss: 0.5431674718856812\n",
      "Iter: 30 \tLoss: 0.5569343566894531\n",
      "Iter: 40 \tLoss: 0.5575302243232727\n",
      "Iter: 50 \tLoss: 0.47414472699165344\n",
      "Iter: 60 \tLoss: 0.45186570286750793\n",
      "Iter: 70 \tLoss: 0.47513678669929504\n",
      "Iter: 80 \tLoss: 0.5224484205245972\n",
      "Iter: 90 \tLoss: 0.49325600266456604\n",
      "Iter: 100 \tLoss: 0.5094631910324097\n",
      "Iter: 110 \tLoss: 0.5006491541862488\n",
      "Iter: 120 \tLoss: 0.5467856526374817\n",
      "Iter: 130 \tLoss: 0.42729800939559937\n",
      "Iter: 140 \tLoss: 0.5199161171913147\n",
      "Iter: 150 \tLoss: 0.49609318375587463\n",
      "Iter: 160 \tLoss: 0.5241349339485168\n",
      "Iter: 170 \tLoss: 0.5744590163230896\n",
      "Iter: 180 \tLoss: 0.5546752214431763\n",
      "Iter: 190 \tLoss: 0.5115151405334473\n",
      "Iter: 200 \tLoss: 0.5473226308822632\n",
      "Iter: 210 \tLoss: 0.5253011584281921\n",
      "Iter: 220 \tLoss: 0.4773015081882477\n",
      "Mean Train Loss: 0.530561\n",
      "\n",
      "Val Loss: 0.382966 \tAccuracy: 0.87\n",
      "Epoch: 3/20\n",
      "Iter: 0 \tLoss: 0.48992446064949036\n",
      "Iter: 10 \tLoss: 0.4643200933933258\n",
      "Iter: 20 \tLoss: 0.4770963490009308\n",
      "Iter: 30 \tLoss: 0.5296452641487122\n",
      "Iter: 40 \tLoss: 0.4773373305797577\n",
      "Iter: 50 \tLoss: 0.4197860658168793\n",
      "Iter: 60 \tLoss: 0.529582142829895\n",
      "Iter: 70 \tLoss: 0.49230125546455383\n",
      "Iter: 80 \tLoss: 0.5022944211959839\n",
      "Iter: 90 \tLoss: 0.5027862191200256\n",
      "Iter: 100 \tLoss: 0.5379607677459717\n",
      "Iter: 110 \tLoss: 0.5022888779640198\n",
      "Iter: 120 \tLoss: 0.5066109299659729\n",
      "Iter: 130 \tLoss: 0.33360081911087036\n",
      "Iter: 140 \tLoss: 0.526381254196167\n",
      "Iter: 150 \tLoss: 0.5068306922912598\n",
      "Iter: 160 \tLoss: 0.49233755469322205\n",
      "Iter: 170 \tLoss: 0.5466607213020325\n",
      "Iter: 180 \tLoss: 0.6043237447738647\n",
      "Iter: 190 \tLoss: 0.5189811587333679\n",
      "Iter: 200 \tLoss: 0.42637941241264343\n",
      "Iter: 210 \tLoss: 0.4900239109992981\n",
      "Iter: 220 \tLoss: 0.5207825303077698\n",
      "Mean Train Loss: 0.501246\n",
      "\n",
      "Val Loss: 0.372382 \tAccuracy: 0.87\n",
      "Epoch: 4/20\n",
      "Iter: 0 \tLoss: 0.38982561230659485\n",
      "Iter: 10 \tLoss: 0.4858856797218323\n",
      "Iter: 20 \tLoss: 0.4889695346355438\n",
      "Iter: 30 \tLoss: 0.5769527554512024\n",
      "Iter: 40 \tLoss: 0.39862000942230225\n",
      "Iter: 50 \tLoss: 0.5346315503120422\n",
      "Iter: 60 \tLoss: 0.5002058148384094\n",
      "Iter: 70 \tLoss: 0.4254195988178253\n",
      "Iter: 80 \tLoss: 0.5754621028900146\n",
      "Iter: 90 \tLoss: 0.45717301964759827\n",
      "Iter: 100 \tLoss: 0.42073506116867065\n",
      "Iter: 110 \tLoss: 0.49274182319641113\n",
      "Iter: 120 \tLoss: 0.4719496965408325\n",
      "Iter: 130 \tLoss: 0.43879029154777527\n",
      "Iter: 140 \tLoss: 0.42433974146842957\n",
      "Iter: 150 \tLoss: 0.5162423253059387\n",
      "Iter: 160 \tLoss: 0.48556503653526306\n",
      "Iter: 170 \tLoss: 0.4960532486438751\n",
      "Iter: 180 \tLoss: 0.4340530037879944\n",
      "Iter: 190 \tLoss: 0.4491899013519287\n",
      "Iter: 200 \tLoss: 0.5411679744720459\n",
      "Iter: 210 \tLoss: 0.4372907876968384\n",
      "Iter: 220 \tLoss: 0.4637371599674225\n",
      "Mean Train Loss: 0.480451\n",
      "\n",
      "Val Loss: 0.360339 \tAccuracy: 0.88\n",
      "Epoch: 5/20\n",
      "Iter: 0 \tLoss: 0.433639258146286\n",
      "Iter: 10 \tLoss: 0.45821690559387207\n",
      "Iter: 20 \tLoss: 0.5613647699356079\n",
      "Iter: 30 \tLoss: 0.5272232890129089\n",
      "Iter: 40 \tLoss: 0.406672865152359\n",
      "Iter: 50 \tLoss: 0.48176702857017517\n",
      "Iter: 60 \tLoss: 0.42297688126564026\n",
      "Iter: 70 \tLoss: 0.47463086247444153\n",
      "Iter: 80 \tLoss: 0.4653003513813019\n",
      "Iter: 90 \tLoss: 0.39164695143699646\n",
      "Iter: 100 \tLoss: 0.4386904239654541\n",
      "Iter: 110 \tLoss: 0.4945058524608612\n",
      "Iter: 120 \tLoss: 0.5694756507873535\n",
      "Iter: 130 \tLoss: 0.4731922447681427\n",
      "Iter: 140 \tLoss: 0.5514793395996094\n",
      "Iter: 150 \tLoss: 0.5109177231788635\n",
      "Iter: 160 \tLoss: 0.5984569787979126\n",
      "Iter: 170 \tLoss: 0.5086830854415894\n",
      "Iter: 180 \tLoss: 0.5212321877479553\n",
      "Iter: 190 \tLoss: 0.4935954809188843\n",
      "Iter: 200 \tLoss: 0.4398467540740967\n",
      "Iter: 210 \tLoss: 0.46673646569252014\n",
      "Iter: 220 \tLoss: 0.3946709632873535\n",
      "Mean Train Loss: 0.468635\n",
      "\n",
      "Val Loss: 0.359280 \tAccuracy: 0.87\n",
      "Epoch: 6/20\n",
      "Iter: 0 \tLoss: 0.4430540204048157\n",
      "Iter: 10 \tLoss: 0.48068034648895264\n",
      "Iter: 20 \tLoss: 0.4624128043651581\n",
      "Iter: 30 \tLoss: 0.47169896960258484\n",
      "Iter: 40 \tLoss: 0.4626534581184387\n",
      "Iter: 50 \tLoss: 0.399188369512558\n",
      "Iter: 60 \tLoss: 0.4948429465293884\n",
      "Iter: 70 \tLoss: 0.483012318611145\n",
      "Iter: 80 \tLoss: 0.44457483291625977\n",
      "Iter: 90 \tLoss: 0.4527447819709778\n",
      "Iter: 100 \tLoss: 0.4133642613887787\n",
      "Iter: 110 \tLoss: 0.4369376599788666\n",
      "Iter: 120 \tLoss: 0.44180941581726074\n",
      "Iter: 130 \tLoss: 0.3829016387462616\n",
      "Iter: 140 \tLoss: 0.4310322105884552\n",
      "Iter: 150 \tLoss: 0.4810016453266144\n",
      "Iter: 160 \tLoss: 0.5347427725791931\n",
      "Iter: 170 \tLoss: 0.4530736207962036\n",
      "Iter: 180 \tLoss: 0.44557735323905945\n",
      "Iter: 190 \tLoss: 0.5143654942512512\n",
      "Iter: 200 \tLoss: 0.4582035541534424\n",
      "Iter: 210 \tLoss: 0.3784976601600647\n",
      "Iter: 220 \tLoss: 0.3794310390949249\n",
      "Mean Train Loss: 0.455781\n",
      "\n",
      "Val Loss: 0.352055 \tAccuracy: 0.88\n",
      "Epoch: 7/20\n",
      "Iter: 0 \tLoss: 0.417010098695755\n",
      "Iter: 10 \tLoss: 0.4133380949497223\n",
      "Iter: 20 \tLoss: 0.43407532572746277\n",
      "Iter: 30 \tLoss: 0.3751065135002136\n",
      "Iter: 40 \tLoss: 0.5261684060096741\n",
      "Iter: 50 \tLoss: 0.4205770790576935\n",
      "Iter: 60 \tLoss: 0.4102027714252472\n",
      "Iter: 70 \tLoss: 0.40147215127944946\n",
      "Iter: 80 \tLoss: 0.38437801599502563\n",
      "Iter: 90 \tLoss: 0.42175060510635376\n",
      "Iter: 100 \tLoss: 0.4456752836704254\n",
      "Iter: 110 \tLoss: 0.46380069851875305\n",
      "Iter: 120 \tLoss: 0.4088710844516754\n",
      "Iter: 130 \tLoss: 0.3912930488586426\n",
      "Iter: 140 \tLoss: 0.4618546962738037\n",
      "Iter: 150 \tLoss: 0.5049242377281189\n",
      "Iter: 160 \tLoss: 0.4063413143157959\n",
      "Iter: 170 \tLoss: 0.45680496096611023\n",
      "Iter: 180 \tLoss: 0.5543363094329834\n",
      "Iter: 190 \tLoss: 0.4534217119216919\n",
      "Iter: 200 \tLoss: 0.42501482367515564\n",
      "Iter: 210 \tLoss: 0.3706260323524475\n",
      "Iter: 220 \tLoss: 0.4404805600643158\n",
      "Mean Train Loss: 0.447401\n",
      "\n",
      "Val Loss: 0.351367 \tAccuracy: 0.88\n",
      "Epoch: 8/20\n",
      "Iter: 0 \tLoss: 0.3582887351512909\n",
      "Iter: 10 \tLoss: 0.3655060827732086\n",
      "Iter: 20 \tLoss: 0.46491068601608276\n",
      "Iter: 30 \tLoss: 0.4368757903575897\n",
      "Iter: 40 \tLoss: 0.4885605573654175\n",
      "Iter: 50 \tLoss: 0.48047947883605957\n",
      "Iter: 60 \tLoss: 0.4183224141597748\n",
      "Iter: 70 \tLoss: 0.44277524948120117\n",
      "Iter: 80 \tLoss: 0.3145500421524048\n",
      "Iter: 90 \tLoss: 0.5211155414581299\n",
      "Iter: 100 \tLoss: 0.4047321677207947\n",
      "Iter: 110 \tLoss: 0.3795561194419861\n",
      "Iter: 120 \tLoss: 0.41683968901634216\n",
      "Iter: 130 \tLoss: 0.40821754932403564\n",
      "Iter: 140 \tLoss: 0.40535402297973633\n",
      "Iter: 150 \tLoss: 0.4041588306427002\n",
      "Iter: 160 \tLoss: 0.44538387656211853\n",
      "Iter: 170 \tLoss: 0.41040152311325073\n",
      "Iter: 180 \tLoss: 0.41253629326820374\n",
      "Iter: 190 \tLoss: 0.4044797122478485\n",
      "Iter: 200 \tLoss: 0.4855104684829712\n",
      "Iter: 210 \tLoss: 0.43076229095458984\n",
      "Iter: 220 \tLoss: 0.5985308885574341\n",
      "Mean Train Loss: 0.441869\n",
      "\n",
      "Val Loss: 0.350017 \tAccuracy: 0.88\n",
      "Epoch: 9/20\n",
      "Iter: 0 \tLoss: 0.3937586843967438\n",
      "Iter: 10 \tLoss: 0.4952095150947571\n",
      "Iter: 20 \tLoss: 0.4013158977031708\n",
      "Iter: 30 \tLoss: 0.41699180006980896\n",
      "Iter: 40 \tLoss: 0.35243383049964905\n",
      "Iter: 50 \tLoss: 0.3738342523574829\n",
      "Iter: 60 \tLoss: 0.382988840341568\n",
      "Iter: 70 \tLoss: 0.38973188400268555\n",
      "Iter: 80 \tLoss: 0.49117282032966614\n",
      "Iter: 90 \tLoss: 0.4322343170642853\n",
      "Iter: 100 \tLoss: 0.4384124279022217\n",
      "Iter: 110 \tLoss: 0.4444845914840698\n",
      "Iter: 120 \tLoss: 0.42860516905784607\n",
      "Iter: 130 \tLoss: 0.5077931880950928\n",
      "Iter: 140 \tLoss: 0.47538959980010986\n",
      "Iter: 150 \tLoss: 0.3867999315261841\n",
      "Iter: 160 \tLoss: 0.44853779673576355\n",
      "Iter: 170 \tLoss: 0.4200531542301178\n",
      "Iter: 180 \tLoss: 0.40836113691329956\n",
      "Iter: 190 \tLoss: 0.508223295211792\n",
      "Iter: 200 \tLoss: 0.3360849916934967\n",
      "Iter: 210 \tLoss: 0.46319976449012756\n",
      "Iter: 220 \tLoss: 0.3973388075828552\n",
      "Mean Train Loss: 0.433409\n",
      "\n",
      "Val Loss: 0.348942 \tAccuracy: 0.88\n",
      "Epoch: 10/20\n",
      "Iter: 0 \tLoss: 0.459646612405777\n",
      "Iter: 10 \tLoss: 0.41665756702423096\n",
      "Iter: 20 \tLoss: 0.48334380984306335\n",
      "Iter: 30 \tLoss: 0.3675602972507477\n",
      "Iter: 40 \tLoss: 0.34035131335258484\n",
      "Iter: 50 \tLoss: 0.42126619815826416\n",
      "Iter: 60 \tLoss: 0.38276416063308716\n",
      "Iter: 70 \tLoss: 0.4418818950653076\n",
      "Iter: 80 \tLoss: 0.43966078758239746\n",
      "Iter: 90 \tLoss: 0.3618125319480896\n",
      "Iter: 100 \tLoss: 0.41523316502571106\n",
      "Iter: 110 \tLoss: 0.4698186218738556\n",
      "Iter: 120 \tLoss: 0.5019158124923706\n",
      "Iter: 130 \tLoss: 0.4488469362258911\n",
      "Iter: 140 \tLoss: 0.37246325612068176\n",
      "Iter: 150 \tLoss: 0.41660040616989136\n",
      "Iter: 160 \tLoss: 0.47449901700019836\n",
      "Iter: 170 \tLoss: 0.3691677749156952\n",
      "Iter: 180 \tLoss: 0.45234185457229614\n",
      "Iter: 190 \tLoss: 0.5238032937049866\n",
      "Iter: 200 \tLoss: 0.39579999446868896\n",
      "Iter: 210 \tLoss: 0.40763625502586365\n",
      "Iter: 220 \tLoss: 0.3644070327281952\n",
      "Mean Train Loss: 0.423775\n",
      "\n",
      "Val Loss: 0.342571 \tAccuracy: 0.88\n",
      "Epoch: 11/20\n",
      "Iter: 0 \tLoss: 0.4053219258785248\n",
      "Iter: 10 \tLoss: 0.4544631242752075\n",
      "Iter: 20 \tLoss: 0.4194912314414978\n",
      "Iter: 30 \tLoss: 0.41879037022590637\n",
      "Iter: 40 \tLoss: 0.40672990679740906\n",
      "Iter: 50 \tLoss: 0.4508247673511505\n",
      "Iter: 60 \tLoss: 0.45417284965515137\n",
      "Iter: 70 \tLoss: 0.48880472779273987\n",
      "Iter: 80 \tLoss: 0.5593663454055786\n",
      "Iter: 90 \tLoss: 0.4339871108531952\n",
      "Iter: 100 \tLoss: 0.45065397024154663\n",
      "Iter: 110 \tLoss: 0.4806532859802246\n",
      "Iter: 120 \tLoss: 0.3682677745819092\n",
      "Iter: 130 \tLoss: 0.4174206256866455\n",
      "Iter: 140 \tLoss: 0.36359742283821106\n",
      "Iter: 150 \tLoss: 0.42434176802635193\n",
      "Iter: 160 \tLoss: 0.3473716378211975\n",
      "Iter: 170 \tLoss: 0.35399845242500305\n",
      "Iter: 180 \tLoss: 0.48652252554893494\n",
      "Iter: 190 \tLoss: 0.42962679266929626\n",
      "Iter: 200 \tLoss: 0.4096209406852722\n",
      "Iter: 210 \tLoss: 0.4406593441963196\n",
      "Iter: 220 \tLoss: 0.39334794878959656\n",
      "Mean Train Loss: 0.419523\n",
      "\n",
      "Val Loss: 0.340124 \tAccuracy: 0.88\n",
      "Epoch: 12/20\n",
      "Iter: 0 \tLoss: 0.4045388102531433\n",
      "Iter: 10 \tLoss: 0.3704822361469269\n",
      "Iter: 20 \tLoss: 0.42511263489723206\n",
      "Iter: 30 \tLoss: 0.4331936538219452\n",
      "Iter: 40 \tLoss: 0.43093055486679077\n",
      "Iter: 50 \tLoss: 0.3865082263946533\n",
      "Iter: 60 \tLoss: 0.40799587965011597\n",
      "Iter: 70 \tLoss: 0.40397149324417114\n",
      "Iter: 80 \tLoss: 0.3731471300125122\n",
      "Iter: 90 \tLoss: 0.3690234124660492\n",
      "Iter: 100 \tLoss: 0.3916071057319641\n",
      "Iter: 110 \tLoss: 0.4959474205970764\n",
      "Iter: 120 \tLoss: 0.41267386078834534\n",
      "Iter: 130 \tLoss: 0.33626195788383484\n",
      "Iter: 140 \tLoss: 0.5144715905189514\n",
      "Iter: 150 \tLoss: 0.4580986797809601\n",
      "Iter: 160 \tLoss: 0.40983277559280396\n",
      "Iter: 170 \tLoss: 0.3893566429615021\n",
      "Iter: 180 \tLoss: 0.40148019790649414\n",
      "Iter: 190 \tLoss: 0.40320929884910583\n",
      "Iter: 200 \tLoss: 0.36441630125045776\n",
      "Iter: 210 \tLoss: 0.455471009016037\n",
      "Iter: 220 \tLoss: 0.41189712285995483\n",
      "Mean Train Loss: 0.417488\n",
      "\n",
      "Val Loss: 0.337851 \tAccuracy: 0.88\n",
      "Epoch: 13/20\n",
      "Iter: 0 \tLoss: 0.4250966012477875\n",
      "Iter: 10 \tLoss: 0.44084107875823975\n",
      "Iter: 20 \tLoss: 0.43762725591659546\n",
      "Iter: 30 \tLoss: 0.5071371793746948\n",
      "Iter: 40 \tLoss: 0.43889912962913513\n",
      "Iter: 50 \tLoss: 0.4768441319465637\n",
      "Iter: 60 \tLoss: 0.3915117084980011\n",
      "Iter: 70 \tLoss: 0.41265782713890076\n",
      "Iter: 80 \tLoss: 0.4608060419559479\n",
      "Iter: 90 \tLoss: 0.39335009455680847\n",
      "Iter: 100 \tLoss: 0.4044976532459259\n",
      "Iter: 110 \tLoss: 0.3704046607017517\n",
      "Iter: 120 \tLoss: 0.4389866590499878\n",
      "Iter: 130 \tLoss: 0.4609707295894623\n",
      "Iter: 140 \tLoss: 0.3535754084587097\n",
      "Iter: 150 \tLoss: 0.4293401837348938\n",
      "Iter: 160 \tLoss: 0.41890156269073486\n",
      "Iter: 170 \tLoss: 0.4444155991077423\n",
      "Iter: 180 \tLoss: 0.41143113374710083\n",
      "Iter: 190 \tLoss: 0.44367673993110657\n",
      "Iter: 200 \tLoss: 0.39339694380760193\n",
      "Iter: 210 \tLoss: 0.381935715675354\n",
      "Iter: 220 \tLoss: 0.481881707906723\n",
      "Mean Train Loss: 0.414636\n",
      "\n",
      "Val Loss: 0.336140 \tAccuracy: 0.88\n",
      "Epoch: 14/20\n",
      "Iter: 0 \tLoss: 0.4234366714954376\n",
      "Iter: 10 \tLoss: 0.4171922206878662\n",
      "Iter: 20 \tLoss: 0.37407514452934265\n",
      "Iter: 30 \tLoss: 0.36519259214401245\n",
      "Iter: 40 \tLoss: 0.3874913454055786\n",
      "Iter: 50 \tLoss: 0.37698695063591003\n",
      "Iter: 60 \tLoss: 0.40786871314048767\n",
      "Iter: 70 \tLoss: 0.3985903561115265\n",
      "Iter: 80 \tLoss: 0.3848087191581726\n",
      "Iter: 90 \tLoss: 0.43868300318717957\n",
      "Iter: 100 \tLoss: 0.39558157324790955\n",
      "Iter: 110 \tLoss: 0.396476686000824\n",
      "Iter: 120 \tLoss: 0.3921126425266266\n",
      "Iter: 130 \tLoss: 0.44260746240615845\n",
      "Iter: 140 \tLoss: 0.34846797585487366\n",
      "Iter: 150 \tLoss: 0.4039619266986847\n",
      "Iter: 160 \tLoss: 0.39386385679244995\n",
      "Iter: 170 \tLoss: 0.43561244010925293\n",
      "Iter: 180 \tLoss: 0.36229726672172546\n",
      "Iter: 190 \tLoss: 0.3652462661266327\n",
      "Iter: 200 \tLoss: 0.45650428533554077\n",
      "Iter: 210 \tLoss: 0.4088737964630127\n",
      "Iter: 220 \tLoss: 0.3694228231906891\n",
      "Mean Train Loss: 0.406243\n",
      "\n",
      "Val Loss: 0.338291 \tAccuracy: 0.88\n",
      "Epoch: 15/20\n",
      "Iter: 0 \tLoss: 0.4791097939014435\n",
      "Iter: 10 \tLoss: 0.3969607651233673\n",
      "Iter: 20 \tLoss: 0.31976640224456787\n",
      "Iter: 30 \tLoss: 0.3523779809474945\n",
      "Iter: 40 \tLoss: 0.39845582842826843\n",
      "Iter: 50 \tLoss: 0.39719876646995544\n",
      "Iter: 60 \tLoss: 0.46278226375579834\n",
      "Iter: 70 \tLoss: 0.38731831312179565\n",
      "Iter: 80 \tLoss: 0.36683809757232666\n",
      "Iter: 90 \tLoss: 0.38075441122055054\n",
      "Iter: 100 \tLoss: 0.36615729331970215\n",
      "Iter: 110 \tLoss: 0.45881757140159607\n",
      "Iter: 120 \tLoss: 0.36524108052253723\n",
      "Iter: 130 \tLoss: 0.4148908257484436\n",
      "Iter: 140 \tLoss: 0.43328848481178284\n",
      "Iter: 150 \tLoss: 0.39895665645599365\n",
      "Iter: 160 \tLoss: 0.3687703013420105\n",
      "Iter: 170 \tLoss: 0.4176170229911804\n",
      "Iter: 180 \tLoss: 0.3686000108718872\n",
      "Iter: 190 \tLoss: 0.4618758261203766\n",
      "Iter: 200 \tLoss: 0.41117510199546814\n",
      "Iter: 210 \tLoss: 0.5234664082527161\n",
      "Iter: 220 \tLoss: 0.4058791697025299\n",
      "Mean Train Loss: 0.403182\n",
      "\n",
      "Val Loss: 0.334193 \tAccuracy: 0.88\n",
      "Epoch: 16/20\n",
      "Iter: 0 \tLoss: 0.3624100089073181\n",
      "Iter: 10 \tLoss: 0.3656158149242401\n",
      "Iter: 20 \tLoss: 0.3785666227340698\n",
      "Iter: 30 \tLoss: 0.4449905753135681\n",
      "Iter: 40 \tLoss: 0.452956885099411\n",
      "Iter: 50 \tLoss: 0.4483206868171692\n",
      "Iter: 60 \tLoss: 0.37438148260116577\n",
      "Iter: 70 \tLoss: 0.386606365442276\n",
      "Iter: 80 \tLoss: 0.3936462104320526\n",
      "Iter: 90 \tLoss: 0.41167229413986206\n",
      "Iter: 100 \tLoss: 0.4056466817855835\n",
      "Iter: 110 \tLoss: 0.38462555408477783\n",
      "Iter: 120 \tLoss: 0.34794947504997253\n",
      "Iter: 130 \tLoss: 0.38255372643470764\n",
      "Iter: 140 \tLoss: 0.3719775974750519\n",
      "Iter: 150 \tLoss: 0.4160239100456238\n",
      "Iter: 160 \tLoss: 0.4153690040111542\n",
      "Iter: 170 \tLoss: 0.484081894159317\n",
      "Iter: 180 \tLoss: 0.45522424578666687\n",
      "Iter: 190 \tLoss: 0.29785600304603577\n",
      "Iter: 200 \tLoss: 0.3594951033592224\n",
      "Iter: 210 \tLoss: 0.3732698857784271\n",
      "Iter: 220 \tLoss: 0.43356552720069885\n",
      "Mean Train Loss: 0.400264\n",
      "\n",
      "Val Loss: 0.333472 \tAccuracy: 0.88\n",
      "Epoch: 17/20\n",
      "Iter: 0 \tLoss: 0.36568737030029297\n",
      "Iter: 10 \tLoss: 0.3728751540184021\n",
      "Iter: 20 \tLoss: 0.3510400056838989\n",
      "Iter: 30 \tLoss: 0.34820836782455444\n",
      "Iter: 40 \tLoss: 0.39388301968574524\n",
      "Iter: 50 \tLoss: 0.4446423351764679\n",
      "Iter: 60 \tLoss: 0.49777618050575256\n",
      "Iter: 70 \tLoss: 0.3333607316017151\n",
      "Iter: 80 \tLoss: 0.4002925455570221\n",
      "Iter: 90 \tLoss: 0.40236762166023254\n",
      "Iter: 100 \tLoss: 0.41596436500549316\n",
      "Iter: 110 \tLoss: 0.3906311094760895\n",
      "Iter: 120 \tLoss: 0.37608593702316284\n",
      "Iter: 130 \tLoss: 0.4373704195022583\n",
      "Iter: 140 \tLoss: 0.36747151613235474\n",
      "Iter: 150 \tLoss: 0.3435615599155426\n",
      "Iter: 160 \tLoss: 0.4091247022151947\n",
      "Iter: 170 \tLoss: 0.37080147862434387\n",
      "Iter: 180 \tLoss: 0.39231258630752563\n",
      "Iter: 190 \tLoss: 0.3675873577594757\n",
      "Iter: 200 \tLoss: 0.3821146786212921\n",
      "Iter: 210 \tLoss: 0.4080386757850647\n",
      "Iter: 220 \tLoss: 0.37572377920150757\n",
      "Mean Train Loss: 0.398410\n",
      "\n",
      "Val Loss: 0.332116 \tAccuracy: 0.88\n",
      "Epoch: 18/20\n",
      "Iter: 0 \tLoss: 0.4161343574523926\n",
      "Iter: 10 \tLoss: 0.3928660452365875\n",
      "Iter: 20 \tLoss: 0.41493460536003113\n",
      "Iter: 30 \tLoss: 0.35129737854003906\n",
      "Iter: 40 \tLoss: 0.39827096462249756\n",
      "Iter: 50 \tLoss: 0.3874504566192627\n",
      "Iter: 60 \tLoss: 0.37213408946990967\n",
      "Iter: 70 \tLoss: 0.3759671151638031\n",
      "Iter: 80 \tLoss: 0.3519839942455292\n",
      "Iter: 90 \tLoss: 0.3975571393966675\n",
      "Iter: 100 \tLoss: 0.44367775321006775\n",
      "Iter: 110 \tLoss: 0.350331574678421\n",
      "Iter: 120 \tLoss: 0.4089709222316742\n",
      "Iter: 130 \tLoss: 0.389421671628952\n",
      "Iter: 140 \tLoss: 0.4590056538581848\n",
      "Iter: 150 \tLoss: 0.42721182107925415\n",
      "Iter: 160 \tLoss: 0.4135085940361023\n",
      "Iter: 170 \tLoss: 0.42390814423561096\n",
      "Iter: 180 \tLoss: 0.4081669747829437\n",
      "Iter: 190 \tLoss: 0.37890711426734924\n",
      "Iter: 200 \tLoss: 0.3746371269226074\n",
      "Iter: 210 \tLoss: 0.4044448137283325\n",
      "Iter: 220 \tLoss: 0.4438174366950989\n",
      "Mean Train Loss: 0.393936\n",
      "\n",
      "Val Loss: 0.329821 \tAccuracy: 0.88\n",
      "Epoch: 19/20\n",
      "Iter: 0 \tLoss: 0.41191279888153076\n",
      "Iter: 10 \tLoss: 0.36534440517425537\n",
      "Iter: 20 \tLoss: 0.4319910407066345\n",
      "Iter: 30 \tLoss: 0.38177353143692017\n",
      "Iter: 40 \tLoss: 0.39786434173583984\n",
      "Iter: 50 \tLoss: 0.3508498966693878\n",
      "Iter: 60 \tLoss: 0.36631715297698975\n",
      "Iter: 70 \tLoss: 0.3991182744503021\n",
      "Iter: 80 \tLoss: 0.3685387969017029\n",
      "Iter: 90 \tLoss: 0.4008975625038147\n",
      "Iter: 100 \tLoss: 0.366794228553772\n",
      "Iter: 110 \tLoss: 0.4464067220687866\n",
      "Iter: 120 \tLoss: 0.4118874967098236\n",
      "Iter: 130 \tLoss: 0.36664363741874695\n",
      "Iter: 140 \tLoss: 0.4694119989871979\n",
      "Iter: 150 \tLoss: 0.38916876912117004\n",
      "Iter: 160 \tLoss: 0.3642137050628662\n",
      "Iter: 170 \tLoss: 0.34889891743659973\n",
      "Iter: 180 \tLoss: 0.4650208353996277\n",
      "Iter: 190 \tLoss: 0.4390193223953247\n",
      "Iter: 200 \tLoss: 0.37555909156799316\n",
      "Iter: 210 \tLoss: 0.4193415939807892\n",
      "Iter: 220 \tLoss: 0.3456917107105255\n",
      "Mean Train Loss: 0.391089\n",
      "\n",
      "Val Loss: 0.333939 \tAccuracy: 0.88\n",
      "Ранняя остановка на 19 эпохе\n"
     ]
    }
   ],
   "source": [
    "# Оптимизатор и функция потерь\n",
    "loss_f = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "# Параметры обучения\n",
    "n_epoch = 20\n",
    "val_fre = 1\n",
    "\n",
    "# Обучение модели\n",
    "train(model, optimizer, loss_f, train_loader, val_loader, n_epoch, val_fre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3eeee7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1184ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\natas\\AppData\\Local\\Temp\\ipykernel_19432\\762711838.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('model.ckpt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Результаты лучшей модели:\n",
      "Val Loss: 0.333939 \tAccuracy: 0.88\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8817021276595745"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузка лучшей сохранённой модели\n",
    "model.load_state_dict(torch.load('model.ckpt'))\n",
    "\n",
    "# Проверка на валидационном наборе данных\n",
    "print(\"\\nРезультаты лучшей модели:\")\n",
    "validate(model, val_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
